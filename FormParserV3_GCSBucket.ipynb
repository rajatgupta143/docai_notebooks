{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(developer): Uncomment these variables before running the sample.\n",
    "# project_id= 'YOUR_PROJECT_ID'\n",
    "# location = 'YOUR_PROJECT_LOCATION' # Format is 'us' or 'eu'\n",
    "# processor_id = 'YOUR_PROCESSOR_ID' # Create processor in Cloud Console\n",
    "# bucket_name = 'GCS Bucket Name'\n",
    "# file_name = 'FileName.pdf'\n",
    "\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "\n",
    "def process_document(\n",
    "    project_id: str, location: str, processor_id: str, bucket_name:str, file_name: str\n",
    "):\n",
    "\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = documentai.DocumentProcessorServiceClient()\n",
    "\n",
    "    # The full resource name of the processor, e.g.:\n",
    "    # projects/project-id/locations/location/processor/processor-id\n",
    "    # You must create new processors in the Cloud Console first\n",
    "    name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "\n",
    "    image_content = download_blob(bucket_name, file_name).download_as_bytes()\n",
    "    \n",
    "    # Read the file into memory\n",
    "    document = {\"content\": image_content, \"mime_type\": \"application/pdf\"}\n",
    "\n",
    "    # Configure the process request\n",
    "    request = {\"name\": name, \"document\": document}\n",
    "\n",
    "    # Recognizes text entities in the PDF document\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    document = result.document\n",
    "\n",
    "    print(\"Document processing complete.\")\n",
    "\n",
    "    # For a full list of Document object attributes, please reference this page: https://googleapis.dev/python/documentai/latest/_modules/google/cloud/documentai_v1beta3/types/document.html#Document\n",
    "\n",
    "    document_pages = document.pages\n",
    "\n",
    "    # Read the text recognition output from the processor\n",
    "    #print(\"The document contains the following paragraphs:\")\n",
    "    for page in document_pages:\n",
    "        paragraphs = page.paragraphs\n",
    "        for paragraph in paragraphs:\n",
    "            paragraph_text = get_text(paragraph.layout, document)\n",
    "            #print(f\"Paragraph text: {paragraph_text}\")\n",
    "        \n",
    "        print(\"Page Number:{}\".format(page.page_number))\n",
    "        for form_field in page.form_fields:\n",
    "            print('Field Name:{}\\tconfidence: {}'.format(get_text(form_field.field_name,document),form_field.field_name.confidence))\n",
    "            print('Field Value:{}\\tconfidence:{}'.format(get_text(form_field.field_value,document),form_field.field_value.confidence))\n",
    "\n",
    "# Extract shards from the text field\n",
    "def get_text(doc_element: dict, document: dict):\n",
    "    \"\"\"\n",
    "    Document AI identifies form fields by their offsets\n",
    "    in document text. This function converts offsets\n",
    "    to text snippets.\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    for segment in doc_element.text_anchor.text_segments:\n",
    "        start_index = (\n",
    "            int(segment.start_index)\n",
    "            if segment in doc_element.text_anchor.text_segments\n",
    "            else 0\n",
    "        )\n",
    "        end_index = int(segment.end_index)\n",
    "        response += document.text[start_index:end_index]\n",
    "    return response\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
